{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED) if torch.cuda.is_available() else None\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../Dataset\"\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUM_WORKERS = 8  # Adjust based on your CPU cores\n",
    "PIN_MEMORY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated mean: tensor([0.4671, 0.3818, 0.3416])\n",
      "Calculated std: tensor([0.2814, 0.2570, 0.2542])\n"
     ]
    }
   ],
   "source": [
    "transform_for_stats = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_data_stats = ImageFolder(root=os.path.join(DATASET_PATH, \"Train\"), transform=transform_for_stats)\n",
    "train_loader_stats = DataLoader(train_data_stats, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "num_batches = 0\n",
    "\n",
    "for batch, _ in train_loader_stats:\n",
    "    mean += batch.mean(dim=(0, 2, 3))\n",
    "    std += batch.std(dim=(0, 2, 3))\n",
    "    num_batches += 1\n",
    "\n",
    "mean /= num_batches\n",
    "std /= num_batches\n",
    "\n",
    "print(f\"Calculated mean: {mean}\")\n",
    "print(f\"Calculated std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4671, 0.3818, 0.3416], std=[0.2814, 0.2570, 0.2542])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4671, 0.3818, 0.3416], std=[0.2814, 0.2570, 0.2542])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Number of training examples: 140002\n",
      "Number of validation examples: 39428\n",
      "Number of testing examples: 10905\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "train_data = ImageFolder(root=os.path.join(DATASET_PATH, \"Train\"), transform=train_transforms)\n",
    "val_data = ImageFolder(root=os.path.join(DATASET_PATH, \"Validation\"), transform=test_transforms)\n",
    "test_data = ImageFolder(root=os.path.join(DATASET_PATH, \"Test\"), transform=test_transforms)\n",
    "\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(val_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    prefetch_factor=4 if NUM_WORKERS > 0 else None,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    prefetch_factor=4 if NUM_WORKERS > 0 else None\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    prefetch_factor=4 if NUM_WORKERS > 0 else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeRestNetDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load pretrained ResNet50\n",
    "        self.backbone = torchvision.models.resnet50(weights='DEFAULT')\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Simple classifier head - minimal modification\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # For calculating running accuracy during evaluation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Create tqdm progress bar\n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(loader, desc=\"Evaluating\")\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        batch_size = images.size(0)\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        if hasattr(torch, 'channels_last') and torch.cuda.is_available():\n",
    "            images = images.to(memory_format=torch.channels_last)\n",
    "            \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "        \n",
    "        # Handle case when batch size is 1\n",
    "        if probs.ndim == 0:\n",
    "            probs = probs.unsqueeze(0)\n",
    "            \n",
    "        # Get binary predictions\n",
    "        preds = (probs >= 0.5).int()\n",
    "        \n",
    "        # Calculate batch accuracy\n",
    "        batch_correct = (preds.cpu() == labels).sum().item()\n",
    "        correct += batch_correct\n",
    "        total += batch_size\n",
    "        \n",
    "        # Store for final metrics\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_targets.append(labels.cpu().numpy())\n",
    "        \n",
    "        # Update progress bar with current accuracy\n",
    "        current_accuracy = correct / total\n",
    "        pbar.set_postfix({\n",
    "            'Acc': f'{current_accuracy:.4f}',\n",
    "            'Imgs/sec': f'{total / (time.time() - start_time):.1f}'\n",
    "        })\n",
    "    \n",
    "    # Final evaluation\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    final_accuracy = accuracy_score(all_targets, (all_probs >= 0.5).astype(int))\n",
    "    auc = roc_auc_score(all_targets, all_probs)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nEvaluation completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Average time per image: {total_time/len(all_targets):.4f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': final_accuracy,\n",
    "        'auc': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "    \n",
    "# Create model\n",
    "model = DeepFakeRestNetDetector().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Starting evaluation on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 86/86 [20:50<00:00, 14.54s/it, Acc=0.5075, Imgs/sec=8.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed in 1250.88 seconds\n",
      "Average time per image: 0.1147 seconds\n",
      "\n",
      "===== RESULTS =====\n",
      "Final Accuracy: 0.5075\n",
      "AUC-ROC Score: 0.5173\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if hasattr(torch, 'compile') and torch.cuda.is_available():\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "            print(\"Model compiled successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model compilation failed: {e}. Continuing with standard model.\")\n",
    "    \n",
    "    # Start evaluation\n",
    "print(\"-\" * 50)\n",
    "print(\"Starting evaluation on test set...\")\n",
    "results = evaluate(model, test_loader, device)\n",
    "    \n",
    "print(\"\\n===== RESULTS =====\")\n",
    "print(f\"Final Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"AUC-ROC Score: {results['auc']:.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
